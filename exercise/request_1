#实例1：爬取京东商品详情页
import requests
url='http://item.jd.com/2967929.html'
try:
    r=requests.get(url)
    r.raise_for_status()  #检查Response状态码,若不是200则产生HttpError异常
    r.encoding=r.apparent_encoding
    print(r.text[:1000])
except:
    print("爬取失败")


url='https://www.amazon.cn/dp/B076YGLN6G?smid=A3CQWPW49OI3BQ&ref_=Oct_CBBBCard_dsk_asin2&pf_rd_r=X83064H6KVVDTZ4WWDFB&pf_rd_p=5a0738df-7719-4914-81ee-278221dce082&pf_rd_m=A1AJ19PSB66TGU&pf_rd_s=desktop-3'
try:
    res = requests.get(url)
    res.raise_for_status()        #503
    res.encoding=r.apparent_encoding   #'ISO-8859-1'
    print(res.text[:1000])
except:
    print("爬取错误")

'''
res.request.headers
Out[7]: {'User-Agent': 'python-requests/2.22.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
'''

try:
    kv={'user-agent':'Mozilla/5.0'}  #浏览器身份标识的字段
    r=requests.get(url,headers=kv)
    r.raise_for_status()  #r.status_code   200
    r.encoding=r.apparent_encoding
    print(r.text[1000:3000])
except:
    print("爬取失败")



# import requests
# from bs4 import BeautifulSoup
# import bs4
#
# #爬取信息
# def getHtmlText(url):
#   try:
#     res=requests.get(url,timeout=30)
#     res.raise_for_status()
#     res.encoding=res.apparent_encoding
#     return res.text
#   except:
#     print("error")
#     return ""
#
# #提取信息
# def fillUnivList(ulist,html):
#   soup=BeautifulSoup(html,"html.parser")
#   for tr in soup.find("tbody").children:
#     if isinstance(tr,bs4.element.Tag): #检测tr标签的类型
#       tds=tr('td')
#       ulist.append([tds[0].string,tds[1].string,tds[2].string])
#
# #打印信息
# def printUnivList(ulist,num): #学习数量
#   tplt="{0:^10}\t{1:{3}^12}\t{2:^9}" #{}域，格式化输出
#   #表头
#   print(tplt.format("排名","学校","地址",chr(12288)))
#   for i in range(num):
#     u=ulist[i]
#     print(tplt.format(u[0],u[1],u[2],chr(12288)))
#   print("Suc"+str(num))
#
# #chr(12288)中文空格，解决中英文混排的问题
#
# def mian():
#   uinfo=[]
#   url='http://www.zuihaodaxue.com/zuihaodaxuepaiming2019.html'
#   html=getHtmlText(url)
#   fillUnivList(uinfo,html)
#   printUnivList(uinfo,20)
# mian()

